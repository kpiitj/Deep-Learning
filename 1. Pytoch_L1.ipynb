{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "glyPMki6WKHf",
        "Yre7nTd5XerK",
        "F4XWsGETZkcZ",
        "9O6A6tjKaPTX",
        "9hS4T3CRuSAo",
        "fHRXwauWxSJw",
        "GEPR3Qle7kAW",
        "j5QdTMc18uuh"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## What is PyTorch?\n",
        "\n",
        "1. PyTorch is a Python-based scientific computing package.\n",
        "2. It utilizes GPU acceleration for high-performance computing.\n",
        "\n",
        "#### Why is PyTorch Popular?\n",
        "\n",
        "1. It is a preferred platform for deep learning research.\n",
        "2. Offers maximum flexibility and speed for model development.\n",
        "\n",
        "#### Key Features of PyTorch:\n",
        "\n",
        "1. Tensor computations with strong GPU acceleration.\n",
        "2. Deep neural network building using a tape-based autograd system."
      ],
      "metadata": {
        "id": "z5Ju6XriGh7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__A tape-based autograd system__ in PyTorch refers to its dynamic computation graph, which records operations as they happen and allows efficient backpropagation for computing gradients.\n",
        "\n",
        "1. __What is Autograd?__\n",
        "- Autograd (short for automatic differentiation) is PyTorch’s automatic differentiation engine.\n",
        "- It keeps track of operations on tensors and allows automatic gradient computation.\n",
        "2. __What is a Tape-Based Autograd System?__\n",
        "- PyTorch records (or \"writes\") operations on a computational tape while executing them.\n",
        "- When you call .backward(), PyTorch reads the tape in reverse to compute gradients using the chain rule.\n",
        "- This is also called define-by-run, meaning the graph is dynamically built during execution.\n"
      ],
      "metadata": {
        "id": "h4z6dpqtUFvt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fWBVA_R8q1s"
      },
      "source": [
        "## Brief History about PyTorch\n",
        "\n",
        "1. __Adoption and Popularity of PyTorch__\n",
        "-> Released in January 2016, PyTorch has been increasingly adopted by researchers. </br>\n",
        "-> It has become a go-to library for building complex neural networks.\n",
        "Competing strongly with TensorFlow, especially in research.\n",
        "Still considered new and evolving, so mass adoption is ongoing.\n",
        "2. __Design Philosophy__\n",
        "-> PyTorch was designed to be imperative, meaning it runs computations dynamically. </br>\n",
        "-> This approach fits well with Python, making it intuitive and easy to use. </br>\n",
        "-> Scientists, ML developers, and debuggers can test parts of their code in real-time. </br>\n",
        "Unlike static computation graphs, PyTorch does not require re-executing the entire code for debugging.\n",
        "3. __Extensibility with Python Libraries__\n",
        "-> PyTorch seamlessly integrates with Python libraries such as: </br>\n",
        "    NumPy (numerical computing) </br>\n",
        "    SciPy (scientific computing) </br>\n",
        "    Cython (performance optimization) </br>\n",
        "4. __Why PyTorch for Deep Learning?__\n",
        "-> Highly dynamic – Models can be modified on the go. </br>\n",
        "-> Flexible – Adapts to different research needs and experiments. </br>\n",
        "-> Widely used in the AI community – Adopted by researchers, students, and developers. </br>\n",
        "5. __Real-World Competitions & Adoption__\n",
        "-> In a recent Kaggle competition, nearly all of the top 10 finishers used PyTorch.\n",
        "-> Shows strong real-world effectiveness and industry adoption.\n",
        "\n",
        "Some of the key highlights of PyTorch includes:\n",
        "\n",
        "__Simple Interface:__ It offers easy to use API, thus it is very simple to operate and run like Python.\n",
        "\n",
        "__Pythonic in nature:__ This library, being Pythonic, smoothly integrates with the Python data science stack. Thus it can leverage all the services and functionalities offered by the Python environment.\n",
        "\n",
        "__Computational graphs:__ In addition to this, PyTorch provides an excellent platform which offers dynamic computational graphs, thus you can change them during runtime. This is highly useful when you have no idea how much memory will be required for creating a neural network model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Practice Questions\n",
        "Q1)Write a PyTorch code snippet to create a tensor with requires_grad=True, perform a simple operation, and compute its gradient dynamically."
      ],
      "metadata": {
        "id": "glyPMki6WKHf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EGgFSvGAWW90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2) Show how PyTorch integrates with NumPy by converting a NumPy array into a PyTorch tensor and back."
      ],
      "metadata": {
        "id": "hL95HC-aWVt3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYlEgEvGWtzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAJGOSJ38q1t"
      },
      "source": [
        "## Why we use PyTorch in research field?\n",
        "\n",
        "Anyone who is working in the field of deep learning and artificial intelligence has likely worked with TensorFlow before, Google’s most popular open source library. However, the latest deep learning framework – PyTorch solves major problems in terms of research work. Arguably PyTorch is TensorFlow’s biggest competitor to date, and it is currently a much favored deep learning and artificial intelligence library in the research community.\n",
        "\n",
        "\n",
        "You might be thinking why we use PyTorch? I list down the three factors for that\n",
        "\n",
        "- Easy-to-use API – PyTorch’s syntax is intuitive and Pythonic.\n",
        "- It is highly favored by the research community due to its flexibility.\n",
        "- Dynamic computation graph – Allows on-the-fly model changes without redefining the entire graph."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CPU vs GPU: Key Differences and Use Cases\n",
        "1. Core Architecture\n",
        "\n",
        "- CPU (Central Processing Unit):\n",
        "  - Has fewer but powerful compute cores.\n",
        "  - Optimized for handling single-threaded or lightly parallel tasks.\n",
        "\n",
        "- GPU (Graphics Processing Unit):\n",
        "  - Contains thousands of smaller, less powerful cores.\n",
        "  - Designed for massive parallelization, handling many tasks simultaneously.\n",
        "\n",
        "2. Performance Differences\n",
        "\n",
        "- CPU excels at:\n",
        "  - General-purpose computing (OS operations, application execution).\n",
        "  - Tasks requiring low latency and sequential processing.\n",
        "  - Complex decision-making, branching, and control-heavy tasks.\n",
        "- GPU excels at:\n",
        "  - Deep learning, AI, and scientific computing (e.g., matrix multiplications).\n",
        "  - High-performance tasks that involve parallel computation (e.g., image processing, video rendering).\n",
        "  - Training deep neural networks efficiently.\n",
        "\n",
        "3. Use Cases in Deep Learning\n",
        "\n",
        "- CPU is better for:\n",
        "  - Model inference (especially on small-scale tasks).\n",
        "  - Data preprocessing before feeding data into the model.\n",
        "- GPU is essential for:\n",
        "  - Training deep learning models (significantly speeds up computation).\n",
        "  - Running large-scale AI applications (like image classification and NLP models)."
      ],
      "metadata": {
        "id": "vg1-MGqpM_1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Practice Questions\n",
        "Write a PyTorch code snippet to check if GPU is available and print the device name."
      ],
      "metadata": {
        "id": "Yre7nTd5XerK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mxPMflNtXhsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4SMdw8L8q1u"
      },
      "source": [
        "### Install\n",
        "\n",
        "<mark style=\"background-color: Blue\">__In CPU__</mark>\n",
        "\n",
        "__For Windows__\n",
        "\n",
        "* Install PyTorch using conda\n",
        "      conda install pytorch torchvision cpuonly -c pytorch\n",
        "\n",
        "* Using pip\n",
        "      pip3 install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
        "        \n",
        "__For Mac__\n",
        "\n",
        "* Using conda\n",
        "      conda install pytorch torchvision -c pytorch\n",
        "    \n",
        "* Using pip\n",
        "      pip3 install torch torchvision\n",
        "    \n",
        "__For Linux__\n",
        "\n",
        "* Using conda\n",
        "      conda install pytorch torchvision cpuonly -c pytorch\n",
        "    \n",
        "* Using pip\n",
        "      pip3 install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
        "      \n",
        "      \n",
        "      \n",
        "<mark style=\"background-color: Green\">__In GPU__</mark>\n",
        "\n",
        "__For Windows__\n",
        "\n",
        "* Install PyTorch using conda cuda=9.2 and Python=3.6\n",
        "      conda install pytorch torchvision cudatoolkit=9.2 -c pytorch\n",
        "     \n",
        "* Using conda cuda=10.1 and Python=3.6\n",
        "      conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
        "     \n",
        "* Install Pytorch using pip cuda=9.2 and Python=3.6\n",
        "      pip3 install torch==1.4.0+cu92 torchvision==0.5.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "     \n",
        "* Using pip cuda=10.1 and Python=3.6\n",
        "      pip3 install torch torchvision\n",
        "     \n",
        "__For Linux__\n",
        "\n",
        "* Install PyTorch using conda cuda=9.2 and Python=3.6\n",
        "      conda install pytorch torchvision cudatoolkit=9.2 -c pytorch\n",
        "     \n",
        "* Using conda cuda=10.1 and Python=3.6\n",
        "      conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
        "     \n",
        "* Install Pytorch using pip cuda=9.2 and Python=3.6\n",
        "      pip3 install torch==1.4.0+cu92 torchvision==0.5.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "     \n",
        "* Using pip cuda=10.1 and Python=3.6\n",
        "      pip3 install torch torchvision\n",
        "     \n",
        "__For Mac__\n",
        "\n",
        "* Install PyTorch using conda  for cuda=9.2 and 10.1 we can use same command and Python=3.6\n",
        "\n",
        "      conda install pytorch torchvision -c pytorch\n",
        "         # MacOS Binaries dont support CUDA, install from source if CUDA is needed\n",
        "       \n",
        "* Install Pytorch using pip for cuda=9.2 and 10.1 we can use same command and Python=3.6\n",
        "\n",
        "      pip3 install torch torchvision\n",
        "         # MacOS Binaries dont support CUDA, install from source if CUDA is needed\n",
        "      \n",
        "You have to run all these commands in __Anaconda Prompt__ , if you want to install in a notebook just put \" ! \" mark before the command like: !pip3 install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5wBiUiJ8q1v"
      },
      "source": [
        "For more information about Installation you can go through this site : \"https://pytorch.org/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-xEj_AN8q1w"
      },
      "source": [
        "# Tensors\n",
        "\n",
        "Tensor is similar to Numpy's ndarray, the additional point for Tensors in we can use it in GPUs to accelerate computing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y34wYSzd8q1w"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing a Tensor\n",
        "\n",
        "Tensors can be initialized in various ways. Take a look at the following examples:\n",
        "\n"
      ],
      "metadata": {
        "id": "E119sEPahyuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Directly from data\n",
        "\n",
        "Tensors can be created directly from data. The data type is automatically inferred."
      ],
      "metadata": {
        "id": "ENUlpg7dafL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "Uo-Ve-Plh5-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEE_TqjmobPc",
        "outputId": "bfe0673e-9b1b-465e-fd13-cc77d7213b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-TE_hKiofJ_",
        "outputId": "0a89d46c-7f6f-4ca5-e873-cd428514ae7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Practice Questions\n",
        "\n",
        "Q) Create a 3x3 tensor with all elements equal to 5.\n"
      ],
      "metadata": {
        "id": "F4XWsGETZkcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L8BaZVZtZ5cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 2) Convert a Python list [[10, 20], [30, 40]] into a PyTorch tensor."
      ],
      "metadata": {
        "id": "MLVAFNfyZ-OG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FK8py8bPaAya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From a NumPy array\n",
        "\n",
        "Tensors can be created from NumPy arrays (and vice versa - see `bridge-to-np-label`).\n",
        "\n"
      ],
      "metadata": {
        "id": "FWzCKaguiHD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "-BxM0_OHiJMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M5HZF0Vozgf",
        "outputId": "6ad3465c-d91c-43c3-884b-9142507f0a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Practice Questions\n",
        "1.  Convert a NumPy array of shape (2,3) filled with random numbers into a PyTorch tensor."
      ],
      "metadata": {
        "id": "9O6A6tjKaPTX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WgdlpsTuaeCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Modify the NumPy array and observe whether the PyTorch tensor also changes."
      ],
      "metadata": {
        "id": "g8nlGJIJaics"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6TdpbHs8alir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Convert a PyTorch tensor to a NumPy array and change a value. Observe the behavior."
      ],
      "metadata": {
        "id": "EW0KWSALpSCA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AunYeXEOpS35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From another tensor:\n",
        "\n",
        "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n",
        "\n"
      ],
      "metadata": {
        "id": "KJ6ZKEljiaRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Q2msXAig1H",
        "outputId": "27cf0c80-4865-4abf-9fd5-d7946d86b634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.9169, 0.5625],\n",
            "        [0.0861, 0.5702]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With random or constant values:\n",
        "\n",
        "``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n",
        "\n"
      ],
      "metadata": {
        "id": "q33x6ZpxilbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQCJYDzSis1y",
        "outputId": "7d8af8ab-bb48-4456-b255-f1fc54518be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.3702, 0.5540, 0.4668],\n",
            "        [0.9475, 0.5353, 0.7006]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Practice Questions\n",
        " 1. Create a tensor of shape (4,4) filled with random numbers."
      ],
      "metadata": {
        "id": "9hS4T3CRuSAo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yju9qIfJu7WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create a tensor of shape (3,3) with all values set to 7."
      ],
      "metadata": {
        "id": "LtxidzLCu8wk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XnET_UQguQ8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different Types of Tensors"
      ],
      "metadata": {
        "id": "0EALVy55awqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1D Tensor ---\n",
        "# A 1D tensor is like a vector: a simple list of numbers.\n",
        "tensor_1d = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(\"1D Tensor:\", tensor_1d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRdMiAM8aQ3-",
        "outputId": "1a1e9e06-8c4e-4bfa-d338-991c5d7bb5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1D Tensor: tensor([1., 2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2D Tensor ---\n",
        "# A 2D tensor is like a matrix with rows and columns.\n",
        "tensor_2d = torch.tensor([[1.0, 2.0, 3.0],\n",
        "                            [4.0, 5.0, 6.0]])\n",
        "print(\"\\n2D Tensor:\\n\", tensor_2d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRMiGekAaTc6",
        "outputId": "e5610e09-e886-468f-d5b6-d0a118b8d7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2D Tensor:\n",
            " tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3D Tensor ---\n",
        "# A 3D tensor can be seen as a stack of matrices.\n",
        "# Here, we create a 3D tensor with shape (2, 3, 4): 2 blocks, each of size 3x4.\n",
        "tensor_3d = torch.randn(2, 3, 4)  # random numbers from a normal distribution\n",
        "print(\"\\n3D Tensor:\\n\", tensor_3d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFBE8l7iadPx",
        "outputId": "eb0cf6bc-c80b-444b-85e5-8097a7eb2a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3D Tensor:\n",
            " tensor([[[ 0.5809,  0.7947,  2.2037, -1.7549],\n",
            "         [-1.2282, -0.2222,  0.3969, -0.0517],\n",
            "         [ 0.0241,  0.3391, -1.4028, -1.4311]],\n",
            "\n",
            "        [[ 1.6425,  1.1303,  1.0618,  0.2898],\n",
            "         [ 0.2379, -0.4366, -0.3007, -1.3163],\n",
            "         [-0.1011, -0.1400, -0.6425, -1.8458]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bxXqu2W8q1y"
      },
      "source": [
        "__Note:__ Uninitialized matrix is declared, but doesn't contain definite known values before it is used. When we created an Unintialized matrix, whatever values were allocated inside the memory will apear as the initial values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwS8MKCZ8q1y"
      },
      "source": [
        "Construct 6x3 matrix, uninitialized:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0C3VtQwW8q1y",
        "outputId": "352b2ebe-4022-4ebe-aa78-6b10b48043f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.3269e-02,  4.3098e-41, -2.3269e-02],\n",
            "        [ 4.3098e-41,  4.4842e-44,  0.0000e+00],\n",
            "        [ 8.9683e-44,  0.0000e+00,  5.2973e-34],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.5695e-43,  0.0000e+00,  8.9683e-44],\n",
            "        [ 0.0000e+00,  5.2976e-34,  0.0000e+00]])\n"
          ]
        }
      ],
      "source": [
        "# Create an uninitialized tensor (its values are whatever happens to be in memory)\n",
        "a = torch.empty(6,3)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCu31uYk8q1z"
      },
      "source": [
        "Construct a randomly initialized matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0x5tmbh8q1z",
        "outputId": "46cb0c0a-f05a-4325-810c-8dfb0c8b455f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7956, 0.4431, 0.9687],\n",
            "        [0.4870, 0.0318, 0.1460],\n",
            "        [0.4865, 0.5054, 0.7244],\n",
            "        [0.2810, 0.0887, 0.3486]])\n"
          ]
        }
      ],
      "source": [
        "# Randomly initialized tensor\n",
        "a = torch.rand(4,3)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJqxjdhm8q1z"
      },
      "source": [
        "Construct a matrix filled zeros and of dtype long:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB1gqY8P8q10",
        "outputId": "164b4d08-42f6-4209-8056-8977b489ad8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "# Tensor of zeros with a specific type (long integers)\n",
        "a = torch.zeros(4,3, dtype=torch.long)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUvV7vwF8q10"
      },
      "source": [
        "Construct a tensor with data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoDbjgLl8q10",
        "outputId": "fe6ce03b-5c9a-426e-8182-87e5794c162c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Creating a tensor from data and then using properties from an existing tensor:\n",
        "a = torch.tensor([7.8, 5])\n",
        "type(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkoJYkEB8q10"
      },
      "source": [
        "or we can create new tensor with existing tensor.These methods we reuse its properties of input tensor, e.g. dtype, unless new values are provided by us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdNOMhS58q11",
        "outputId": "933a2cda-f7ae-4346-b3f8-ead854c64db4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-1.1253, -1.6310, -1.5303, -2.2885,  0.3037],\n",
            "        [ 1.1000,  0.8689, -0.3259, -0.0997,  0.6859],\n",
            "        [ 0.4407,  1.3825, -0.0378, -0.4161, -0.3931],\n",
            "        [-0.2030, -0.8292,  0.6071, -2.3429,  1.5022],\n",
            "        [-0.0529,  0.3151,  1.0868, -0.5790,  0.0233],\n",
            "        [-0.8545,  0.3893, -0.2799,  0.8890,  0.4490]])\n"
          ]
        }
      ],
      "source": [
        "# Create a new tensor filled with ones with the same device and (optionally) similar dtype.\n",
        "a = a.new_ones(6,5, dtype=torch.double)    # new methods take in sizes\n",
        "print(a)\n",
        "# Overriding dtype when creating a similar-sized tensor with random numbers\n",
        "a = torch.randn_like(a, dtype=torch.float)  # override dtype\n",
        "print(a)                                    # result will be the same size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Practice Questions\n",
        "Q) Given a tensor x = torch.tensor([[3, 4], [5, 6]]), create a new tensor filled with zeros that has the same shape and dtype as x."
      ],
      "metadata": {
        "id": "8YIIeaBeYXcw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lKQBS56pZINz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) Write a PyTorch code snippet to create a random tensor of the same size as x but with dtype torch.float64."
      ],
      "metadata": {
        "id": "hCTbYtAGs0Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sYt7q5pNs6-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Q) Given a = torch.ones(5, 5), create a new tensor filled with twos that has the same dtype and device as a."
      ],
      "metadata": {
        "id": "aY7rk00stlrw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "679yw4SetoLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attributes of a Tensor\n",
        "\n",
        "Tensor attributes describe their shape, datatype, and the device on which they are stored.\n",
        "\n"
      ],
      "metadata": {
        "id": "hIIc4joRi8j6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfhycaag8q11"
      },
      "source": [
        "Let's get the size:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vyl4hNk8q11",
        "outputId": "bee61773-3dae-4598-8e75-6430299f1517",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 5])\n"
          ]
        }
      ],
      "source": [
        "print(a.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noq7arw98q11"
      },
      "source": [
        "Note: <mark style=\"background-color: Yellow\">torch_size</mark> is actually a tuple, so it supports all tuple operations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaAfGOPcjEuX",
        "outputId": "6c2f6fa8-b712-44d5-bbcc-04759ea5de2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Practice Questions\n",
        "1. Create a 5x5 tensor of random values and check its data type."
      ],
      "metadata": {
        "id": "fHRXwauWxSJw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xxAngqzhxh23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Move a tensor to GPU if available."
      ],
      "metadata": {
        "id": "HPMY7qK7xni7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IfCIGtgVxof3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Create a tensor on the GPU directly and move it back to CPU."
      ],
      "metadata": {
        "id": "bCFKyVS2xpCo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_cuHjXThxs4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiuLTLxd8q11"
      },
      "source": [
        "# Operations\n",
        "\n",
        "There are multiple syntaxes for operations. In the following examples, we used addition operation,\n",
        "\n",
        "Addition: syntax1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jVApojO8q12",
        "outputId": "ef24adc3-cb0e-4200-fc05-686e9e0984d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9014, -1.1094, -1.4968, -1.7054,  0.7191],\n",
            "        [ 1.7385,  1.6336, -0.3041, -0.0910,  0.9552],\n",
            "        [ 0.4912,  1.5289,  0.5098, -0.1031,  0.5646],\n",
            "        [ 0.2225, -0.1237,  1.4326, -1.6106,  2.1531],\n",
            "        [ 0.4764,  0.7488,  1.7340, -0.4951,  0.8451],\n",
            "        [-0.3344,  0.6405,  0.7127,  1.6160,  1.1687]])\n"
          ]
        }
      ],
      "source": [
        "b = torch.rand(6,5)\n",
        "print(a + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fonN4OdU8q12"
      },
      "source": [
        "Addition: syntax2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QucBjj_Q8q12",
        "outputId": "0561b426-52c8-4590-cf43-5f3a20388f66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9014, -1.1094, -1.4968, -1.7054,  0.7191],\n",
            "        [ 1.7385,  1.6336, -0.3041, -0.0910,  0.9552],\n",
            "        [ 0.4912,  1.5289,  0.5098, -0.1031,  0.5646],\n",
            "        [ 0.2225, -0.1237,  1.4326, -1.6106,  2.1531],\n",
            "        [ 0.4764,  0.7488,  1.7340, -0.4951,  0.8451],\n",
            "        [-0.3344,  0.6405,  0.7127,  1.6160,  1.1687]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.add(a,b))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13ri7CYk8q12"
      },
      "source": [
        "Addition: providing an output as an argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TKAS4hq8q13",
        "outputId": "89a56269-811c-4dd9-fb70-38fb61b3f888",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9014, -1.1094, -1.4968, -1.7054,  0.7191],\n",
            "        [ 1.7385,  1.6336, -0.3041, -0.0910,  0.9552],\n",
            "        [ 0.4912,  1.5289,  0.5098, -0.1031,  0.5646],\n",
            "        [ 0.2225, -0.1237,  1.4326, -1.6106,  2.1531],\n",
            "        [ 0.4764,  0.7488,  1.7340, -0.4951,  0.8451],\n",
            "        [-0.3344,  0.6405,  0.7127,  1.6160,  1.1687]])\n"
          ]
        }
      ],
      "source": [
        "result = torch.empty(6, 5)\n",
        "torch.add(a, b, out=result)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm0q7Q4x8q13"
      },
      "source": [
        "Addition: in place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XvBAVkS8q13",
        "outputId": "5fa0b4c1-a53c-4525-ac3e-80768845ae44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9014, -1.1094, -1.4968, -1.7054,  0.7191],\n",
            "        [ 1.7385,  1.6336, -0.3041, -0.0910,  0.9552],\n",
            "        [ 0.4912,  1.5289,  0.5098, -0.1031,  0.5646],\n",
            "        [ 0.2225, -0.1237,  1.4326, -1.6106,  2.1531],\n",
            "        [ 0.4764,  0.7488,  1.7340, -0.4951,  0.8451],\n",
            "        [-0.3344,  0.6405,  0.7127,  1.6160,  1.1687]])\n"
          ]
        }
      ],
      "source": [
        "# adds a to b\n",
        "b.add_(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P37aQRZj8q13"
      },
      "source": [
        "__Note:__ Any operation that mutates a tensor in-place is post-fixed with an <mark style=\"background-color: red\">_.</mark> For example: a.copy_(b), a.b_(), will change a."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Practice Questions\n",
        "1. Perform element-wise multiplication of two tensors of shape (3,3)."
      ],
      "metadata": {
        "id": "Y0hrCPkwz4H5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TtPu3-7z0NFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Subtract one tensor from another using different PyTorch syntax options."
      ],
      "metadata": {
        "id": "FuS16sjb0QaV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1z8czFyP0RS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSxxAHrK8q14"
      },
      "source": [
        "We can use standard NumPy-like indexing with all bells and whistles!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpSZN9Lt8q14",
        "outputId": "2417e1ef-52e9-4a48-bf43-5eef79eb4da3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.5303, -0.3259, -0.0378,  0.6071,  1.0868, -0.2799])\n"
          ]
        }
      ],
      "source": [
        "print(a[:,2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoMW1Ice8q14"
      },
      "source": [
        "Resizing: We can resize or reshape tensor, use <mark style=\"background-color: Yellow\">tensor.view</mark> for that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwxKhD9X8q14",
        "outputId": "2b5e8079-e8f1-4130-f06c-34a88046dec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6051, 0.2225, 0.3018],\n",
            "        [0.6804, 0.2246, 0.3197]])\n",
            "tensor([0.6051, 0.2225, 0.3018, 0.6804, 0.2246, 0.3197])\n",
            "tensor([[0.6051, 0.2225, 0.3018, 0.6804, 0.2246, 0.3197]])\n",
            "torch.Size([2, 3]) torch.Size([6]) torch.Size([1, 6])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(2, 3)\n",
        "b = a.view(6)\n",
        "c = a.view(-1, 6)  # the size -1 is inferred from other dimensions\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(a.size(), b.size(), c.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EI52Nl98q14"
      },
      "source": [
        "If you have one value tensor, use <mark style=\"background-color: Yellow\">.item()</mark> to get the value of the Python number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqvU7ZHh8q14",
        "outputId": "4354232b-734e-4631-f0f6-5a691871c5eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3004])\n",
            "0.3004308044910431\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(1)\n",
        "print(a)\n",
        "print(a.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Practice Questions:\n",
        " 1. Reshape a tensor of shape (2,6) into shape (3,4)\n"
      ],
      "metadata": {
        "id": "ydWaZHLP1PW6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LCLf79Kt1wwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Flatten a 3D tensor into a 1D tensor."
      ],
      "metadata": {
        "id": "1lBBQbW21xwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NDdMgHX310sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAsMVa1u8q19"
      },
      "source": [
        "# NumPy Bridge\n",
        "\n",
        "Converting a Torch Tensor to NumPy array and vice versa is breeze.\n",
        "\n",
        "The Torch Tensor and NumPy array will share their underlying memory locations (if the Torch Tensor is on CPU), and changing one will change the other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A60uXoks8q1-"
      },
      "source": [
        "## Converting a Torch tensor to NumPy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg4rfTUi8q1-",
        "outputId": "19f18782-9e0d-4598-cd16-15e7ef6890da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(4)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuyrO0uN8q1_",
        "outputId": "5fb8d592-b6d1-4a00-fe96-7489b5ff9a40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "y = x.numpy()\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhXl7Vhd8q1_"
      },
      "source": [
        "See how numpy array changed in value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fm91wzR8q2A",
        "outputId": "f437ceb4-3cc8-4899-b8f3-4d0ac622e436",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2.])\n",
            "[2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "x.add_(1)\n",
        "print(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Practice Questions\n",
        "1. Convert a NumPy array of shape (3,3) to a PyTorch tensor and back to a NumPy array."
      ],
      "metadata": {
        "id": "wwTCNXpW3iCH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u4NRRqVD30rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Change a PyTorch tensor and check if its NumPy counterpart also changes."
      ],
      "metadata": {
        "id": "pvLEObO034Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JQNejuZj340v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4RamwxI8q2A"
      },
      "source": [
        "## Converting NumPy array to Torch tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKpBehuu8q2A"
      },
      "source": [
        "lets see how changing the numpy array changed the Torch Tensor automatically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD7YXRWm8q2A",
        "outputId": "5ea56d66-4416-4076-e029-d64eccc6cf24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "f = np.ones(4)\n",
        "g = torch.from_numpy(f)\n",
        "np.add(f, 1, out=f)\n",
        "print(f)\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gkMfQUb8q2B"
      },
      "source": [
        "All the Tensors on the CPU except a CharTensor support converting to NumPy and back.\n",
        "\n",
        "__CUDA Tensors__\n",
        "\n",
        "Tensors can be moved onto any device using the <mark style=\"background-color: Yellow\">.to</mark> method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua8fAp8a8q2B"
      },
      "outputs": [],
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Practice Questions\n",
        "1. Check if CUDA is available and move a tensor to the GPU.\n"
      ],
      "metadata": {
        "id": "Olt-TxS94Kgq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2JnAT0BS4Uac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Perform a matrix multiplication on GPU and move the result back to CPU."
      ],
      "metadata": {
        "id": "zsV-Ce354U8X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BuZIuRdd4Xxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Create a large tensor (1000x1000) on GPU, compute its mean, and move the result to CPU."
      ],
      "metadata": {
        "id": "8jyU1gsK4lhm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1h91iEsM4mew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_813f8Dj8q2B"
      },
      "source": [
        "# AUTOGRAD : Automatic Differentiaition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL1iw8Ig8q2B"
      },
      "source": [
        "Definition -\n",
        "\n",
        "  - This class is an engine to calculate derivatives. It records the graph of all the operations performed on a gradient      enabled tensor and creates a acyclic graph called the dynamic computational graph(DCG).The leaves of this graph are input tensors and the roots are output tensors. Gradients are calculated by tracing the graph from the root to the leaf and multiplying every gradient in the way using the chain rule."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krTVdoFE8q2B"
      },
      "source": [
        "Let us see this in some more easy terms with some examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVdXe11k8q2C"
      },
      "source": [
        "## Tensor\n",
        "\n",
        "<mark style=\"background-color: Yellow\">torch.Tensor</mark> is the central class of the package.If we set its attribute <mark style=\"background-color: Yellow\">.requires_grad</mark> as <mark style=\"background-color: dark grey\">True</mark>, it starts to track all operations on it. When you finish your computation you can call <mark style=\"background-color: Yellow\">.backward()</mark> and have all the gradients computed automatically. The gradient of this tensor will be accumulated into <mark style=\"background-color: Yellow\">.grad</mark> attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpkhcdWt8q2C"
      },
      "source": [
        "To stop a tensor from tracking history, you can call <mark style=\"background-color: Yellow\">.detach()</mark> to detach it from the computation history, and to prevent future computation from being tracked.\n",
        "\n",
        "\n",
        "To prevent tracking history(and using memory), you can also wrap the code block in with <mark style=\"background-color: Yellow\">torch.no_grad():</mark>. This can be particularly helpful when evaluating a model because the model may have trainable parameters with <mark style=\"background-color: Yellow\">requires_grad=True</mark>, but for which we don’t need the gradients.\n",
        "\n",
        "There's one more class which is very important in autograd implementation - a <mark style=\"background-color: Yellow\">Function</mark>\n",
        "\n",
        "<mark style=\"background-color: Yellow\">Tensor</mark> and <mark style=\"background-color: Yellow\">Function</mark> are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each tensor has a <mark style=\"background-color: Yellow\">.grad_fn</mark> attribute that references a Function that has created the Tensor (except for Tensors created by the user - their <mark style=\"background-color: Yellow\">grad_fn is None</mark>).\n",
        "\n",
        "If you want to compute the derivatives, you can call <mark style=\"background-color: Yellow\">.backward()</mark> on a <mark style=\"background-color: Yellow\">Tensor</mark>. If <mark style=\"background-color: Yellow\">Tensor</mark> is a scalar (i.e. it holds a one element data), you don’t need to specify any arguments to <mark style=\"background-color: Yellow\">backward()</mark>, however if it has more elements, you need to specify a <mark style=\"background-color: Yellow\">gradient</mark> argument that is a tensor of matching shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEqUbMz78q2C"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYCK-v9T8q2C"
      },
      "source": [
        "Create a tensor and set requires_grad=True to track computation with it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaQ8ogFY8q2D",
        "outputId": "ab60bb33-29a8-4a46-d48e-e02861c8c41b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(2, 2, requires_grad=True)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocgj8BIc8q2D"
      },
      "source": [
        "Do a tensor operation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1lh7k8i8q2D",
        "outputId": "29af055a-a6d6-433c-ef9e-06858f898e9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "b = a + 2\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baBHLtX78q2E"
      },
      "source": [
        "b was created as a result of an operatio, so it has a <mark style=\"background-color: Yellow\">grad_fn</mark>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF_BxhTL8q2E",
        "outputId": "5809be1b-c6ee-46e3-8d9b-2be7d0c4f612",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7823bb260370>\n"
          ]
        }
      ],
      "source": [
        "print(b.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3TLUlXR8q2E"
      },
      "source": [
        "Do more operation on b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoV6w-zd8q2E",
        "outputId": "5eb47f47-1537-4c3c-8e23-b27ae4aabdbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "c = b * b * 3\n",
        "out = c.mean()\n",
        "\n",
        "print(c, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "816RYUzT8q2E"
      },
      "source": [
        "<mark style=\"background-color: Yellow\">.requires_grad_( ... )</mark>  changes an existing Tensor’s <mark style=\"background-color: Yellow\">requires_grad</mark> flag in-place. The input flag defaults to False if not given."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L4gQvgs8q2F",
        "outputId": "f2922dc4-a906-4478-ac95-3d8cb8b52244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7823bb2619c0>\n"
          ]
        }
      ],
      "source": [
        "p = torch.randn(3, 3)\n",
        "p = ((p * 3) / (p - 1))\n",
        "print(p.requires_grad)\n",
        "p.requires_grad_(True)\n",
        "print(p.requires_grad)\n",
        "q = (p * p).sum()\n",
        "print(q.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Practice Questions\n",
        "1. Create a tensor with requires_grad=True and perform some operations on it."
      ],
      "metadata": {
        "id": "_d0UGr9p60qi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7L3PDRQW69Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Perform backpropagation on a scalar output and print the gradients."
      ],
      "metadata": {
        "id": "6gAAtU0N6-Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KXaS4REw7TCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Disable gradient tracking temporarily and show how it affects computation."
      ],
      "metadata": {
        "id": "jlu5BauT7VFo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7crM0_gW7bA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeLXA_Qt8q2F"
      },
      "source": [
        "## Gradients\n",
        "\n",
        "Let's backdrop now. Because <mark style=\"background-color: magenta\">out</mark> contains a single scalar, <mark style=\"background-color: Yellow\">out.backword</mark> is equivalent to  <mark style=\"background-color: Yellow\">out.backward(torch.tensor(1.))</mark>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEP67Nws8q2F"
      },
      "outputs": [],
      "source": [
        "out.backward()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO5QQhyA0Ylg",
        "outputId": "e3259a0b-ecbe-4c3f-93f4-ba78f0bf09d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(27., grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I6vRj7s8q2F"
      },
      "source": [
        "Print gradients d(out)/dx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8jWRNHl8q2F",
        "outputId": "5a625a14-1b6c-48ab-8a58-2123b726c59b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "print(a.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N--l6FJi8q2F"
      },
      "source": [
        "You should have got a matrix of 4.5. Let’s call the out Tensor “o”. We have that\n",
        "\n",
        "$o= \\frac{1}{4} \\sum c_i $ $c_i= 3(a_i+2)^2$  and $c_i|_{a_i=1}= 27$ .\n",
        "\n",
        "Therefore, $\\frac{\\partial_0}{\\partial a_i}=\\frac{3(x_i+2)}{2}$,\n",
        "\n",
        "hence\n",
        "$\\frac{\\partial_0}{\\partial a_i}|_{a_i=1} = \\frac{9}{2} = 4.5$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt2hhFYq8q2G"
      },
      "source": [
        "Now let's have a look at an example of vector-Jacobian product:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Practice Questions\n",
        " 1. Create a tensor with requires_grad=True, perform operations, and compute gradients."
      ],
      "metadata": {
        "id": "GEPR3Qle7kAW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FHFb_yYg777k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create a function f(x) = 3x^3 + 2x^2 - 4x + 5 and compute its gradient at x=2."
      ],
      "metadata": {
        "id": "rKF9VHPV79-A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5_afwu5v8fl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Compute gradients for a 2D tensor and verify results."
      ],
      "metadata": {
        "id": "Tk24N8nn8gfy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g0a-HnVP8ldc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbHIANBN8q2G"
      },
      "source": [
        "# Mathematically - Jacobians and Vectors in PyTorch Autograd\n",
        "\n",
        "## 1. What is a Jacobian Matrix?\n",
        "- A **Jacobian matrix (J)** represents all **possible partial derivatives** of one vector with respect to another.\n",
        "- It defines the **gradient of a vector-valued function** with respect to its inputs.\n",
        "\n",
        "## 2. Understanding the Jacobian Matrix\n",
        "- Suppose we have an **input vector**:\n",
        "\n",
        "  $$\n",
        "  X = [x_1, x_2, ..., x_n]\n",
        "  $$\n",
        "\n",
        "- We pass it through a function \\( f(X) \\) that transforms it into another vector:\n",
        "\n",
        "  $$\n",
        "  Y = f(X) = [y_1, y_2, ..., y_m]\n",
        "  $$\n",
        "\n",
        "- The **Jacobian matrix (J)** contains all the **partial derivatives** of each \\( y_i \\) with respect to \\( x_j \\):\n",
        "\n",
        "  $$\n",
        "  J_{ij} = \\frac{\\partial y_i}{\\partial x_j}\n",
        "  $$\n",
        "\n",
        "- This matrix **describes how each element in \\( Y \\) changes with respect to \\( X \\)**.\n",
        "\n",
        "## 3. Application in PyTorch Autograd\n",
        "- PyTorch’s **autograd engine** computes gradients **efficiently using the Jacobian-vector product**.\n",
        "- Instead of computing the full Jacobian (which can be large), PyTorch efficiently computes:\n",
        "\n",
        "  $$\n",
        "  v^T J\n",
        "  $$\n",
        "\n",
        "  where **\\( v \\)** is an external vector called `grad_tensor`.\n",
        "\n",
        "## 4. Vector-Jacobian Product in PyTorch\n",
        "- Assume that a PyTorch tensor \\( X \\) requires gradients (`requires_grad=True`).\n",
        "- After some operations, it results in a new vector \\( Y = f(X) \\).\n",
        "- To compute the **gradient of a scalar loss \\( l \\) with respect to \\( X \\)**, PyTorch performs:\n",
        "\n",
        "  $$\n",
        "  \\frac{dl}{dX} = v^T J\n",
        "  $$\n",
        "\n",
        "- The vector \\( v \\) (external gradient) is passed to `backward()`.\n",
        "\n",
        "## 5. Why Use Vector-Jacobian Products?\n",
        "- It enables PyTorch to **handle non-scalar outputs** efficiently.\n",
        "- Instead of explicitly forming the **full Jacobian matrix**, PyTorch **computes gradients efficiently by multiplying with an external vector**.\n",
        "- This approach allows **faster computation in deep learning models**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNe9BBmSRyeA"
      },
      "source": [
        "Now let's have a look at an example of vector-Jacobian product:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PBu78mT8q2G",
        "outputId": "351e61ce-795a-4842-fe4d-89877e8abdd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1.], requires_grad=True)\n",
            "tensor([2., 2., 2.], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "# while y.detach().norm() < 1000:\n",
        "#     y = y * 2\n",
        "print(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFL3qtJK8q2G"
      },
      "source": [
        "Now in this case y is no longer a scalar.<mark style=\"background-color: Yellow\">torch.autograd(torch.tensor(1.))</mark> could not compute the full Jacobian directly, but if we just want the vector-Jacobian product, simply pass the vector to backward as argument:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg108OOj8q2J",
        "outputId": "38beed56-cfe9-4b08-a9d5-9aff9e046fd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2.])\n"
          ]
        }
      ],
      "source": [
        "v = torch.tensor([1.0, 1.0, 1.0], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B74h3ui8q2J"
      },
      "source": [
        "You can also stop autograd from tracking history on Tensors with <mark style=\"background-color: Yellow\">.requires_grad=True</mark> either by wrapping the code block in with <mark style=\"background-color: Yellow\">torch.no_grad()</mark>:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1xnwT8s8q2K",
        "outputId": "8114e1f6-740e-43a2-fa19-84c731780cf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLkdM_xp8q2K"
      },
      "source": [
        "Or by using .detach() to get a new Tensor with the same content but that does not require gradients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq2-vO_C8q2L",
        "outputId": "50885d40-cbe4-40de-b0fe-8c350777c07a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Practice Questions\n",
        "1. Compute the Jacobian matrix for a given function using PyTorch."
      ],
      "metadata": {
        "id": "j5QdTMc18uuh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk3uz1mkGOIV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Compute the Hessian matrix for a function using PyTorch."
      ],
      "metadata": {
        "id": "3AGszxuv812o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YI_Z_dyM85nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Use vector-Jacobian product (VJP) to compute gradients efficiently"
      ],
      "metadata": {
        "id": "_6aX4J3Z88Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vkUHQUWo8-gZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}